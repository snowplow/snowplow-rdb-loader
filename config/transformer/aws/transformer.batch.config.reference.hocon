{
  # Path to enriched archive (must be populated separately with run=YYYY-MM-DD-hh-mm-ss-UUID directories) for S3 input
  "input": "s3://bucket/input/",

  # Path to transformer archive
  "output": {
    # Path to transformer output
    "path": "s3://bucket/transformed/",
    # Transformer output compression, GZIP or NONE
    # Optional, default value GZIP
    "compression": "GZIP",
    # number of events per parquet partition
    "maxRecordsPerFile": 10000,
    # This field is optional if it can be resolved with AWS region provider chain.
    # It checks places like env variables, system properties, AWS profile file.
    # https://sdk.amazonaws.com/java/api/latest/software/amazon/awssdk/regions/providers/DefaultAwsRegionProviderChain.html
    "region": "eu-central-1",
    
    # Optional section specifying details about badrows output. When unspecified, badrows are written as files under 'output.path' URI
    "bad": {
    
      # Type of output sink. Either 'kinesis' or 'file'. Optional, default value 'file'. When 'file', badrows are written as files under 'output.path' URI 
      "type": "kinesis",
      
      # Name of the Kinesis stream to write to. Required when Kinesis as output is used 
      "streamName": "bad"
      
      # Optional. Region where the Kinesis stream is located
      # This field is optional if it can be resolved with AWS region provider chain.
      # It checks places like env variables, system properties, AWS profile file.
      # https://sdk.amazonaws.com/java/api/latest/software/amazon/awssdk/regions/providers/DefaultAwsRegionProviderChain.html
      "region": "eu-central-1"
      
      # Optional. Limits the number of events in a single PutRecords Kinesis request.
      # Several requests are made in parallel
      # Maximum allowed: 500
      "recordLimit": 500

      # Optional. Limits the number of bytes in a single PutRecords Kinesis request,
      # including records and partition keys.
      # Several requests are made in parallel
      # Maximum allowed: 5 MB
      "byteLimit": 5242880
      
      # Optional. Policy to retry if writing to kinesis fails with unexepected errors
      "backoffPolicy": {
        "minBackoff": 100 milliseconds
        "maxBackoff": 10 seconds
        "maxRetries": 10
      }

      # Optional. Policy to retry if writing to kinesis exceeds the provisioned throughput.
      "throttledBackoffPolicy": {
        "minBackoff": 100 milliseconds
        "maxBackoff": 1 second
      }
    }
  }
  
  


  # Queue used to communicate with Loader
  "queue": {
    # Type of the queue. It can be either sqs or sns
    "type": "sqs",
    # Name of the sqs queue
    "queueName": "test-sqs",
    # Region of the SQS queue.
    # Optional if it can be resolved with AWS region provider chain.
    "region": "eu-central-1"
  }
  # SNS example:
  #"queue": {
  #  # Type of the queue. It can be either sqs or sns
  #  "type": "sns",
  #  # ARN of SNS topic
  #  "topicArn": "arn:aws:sns:eu-central-1:123456789:test-sns-topic",
  #  # Region of the SNS topic
  #  "region": "eu-central-1"
  #}

  # Configure the way in-batch deduplication is performed
  "deduplication": {
    # Synthetic deduplication reassigns new ids to events with same id-fingerprintt pair
    # Different options can be tried if synthetic deduplication affects performance
    # Synthetic deduplication can only be enabled when natural deduplication is enabled
    "synthetic": {
      # Can be NONE (disable), BROADCAST and JOIN (different low-level implementations)
      "type": "BROADCAST"
      # Do not deduplicate pairs with less-or-equal cardinality
      "cardinality": 1
    }
    # Optional. Default value 'true'. Enable or disable natural deduplication.
    "natural": true
  }

  # Schema-specific format settings (recommended to leave all three groups empty and use TSV as default)
  "formats": {
    # Denotes the type of the transformation (shred or widerow)
    "transformationType": "shred",
    # Format used by default (TSV or JSON)
    # Optional, default value TSV
    "default": "TSV",
    # Schemas to be shredded as JSONs, corresponding JSONPath files must be present. Automigrations will be disabled
    # Optional, default value []
    "json": [
      "iglu:com.acme/json-event/jsonschema/1-0-0",
      "iglu:com.acme/json-event/jsonschema/2-*-*"
    ],
    # Schemas to be shredded as TSVs, presence of the schema on Iglu Server is necessary. Automigartions enabled
    # Optional, default value []
    "tsv": [ ],
    # Schemas that won't be loaded
    # Optional, default value []
    "skip": [
      "iglu:com.acme/skip-event/jsonschema/1-*-*"
    ]
  },
  #"formats": {
  #  # Denotes the type of the transformation (shred or widerow)
  #  "transformationType": "widerow",
  #  # Optional. Denotes output file format when transformationType is 'widerow'.
  #  # Possible values are 'json' and 'parquet'. Default value 'json'.
  #  "fileFormat": "json"
  #}

  # Specifies interval Transformer will work on
  "runInterval": {
    # Optional, Transformer will start to process after given timestamp
    "sinceTimestamp": "2021-10-12-14-55-22",
    # Optional, sinceAge is a duration that specifies the maximum age of folders that
    # should get processed. If sinceAge and sinceTimestamp are both specified, then the
    # latest value of the two determines the earliest folder that will be processed.
    "sinceAge": "14 days",
    # Optional, Transformer will process until given timestamp
    "until": "2021-12-10-18-34-52"
  }

  # Events will be validated against given criterias and
  # bad row will be created if validation is not successful
  "validations": {
    "minimumTimestamp": "2021-11-18T11:00:00.00Z"
  }

  # Optional. Enable features that are still in beta, or which are here to enable smoother upgrades
  "featureFlags": {
    # Read/write in the legacy version 1 shredding complete message format.
    # This should be enabled during upgrade from older versions of the loader.
    "legacyMessageFormat": false,
    
    # When enables `maxRecordsPerFile` configuration parameter is going to be used
    "enableMaxRecordsPerFile": false
    
    # When enabled, event's atomic fields are truncated (based on the length limits from the atomic JSON schema) before transformation.
    # Optional, default "false".
    "truncateAtomicFields": false
  }

  # Observability and reporting options
  "monitoring": {
    # Optional, for tracking runtime exceptions
    "sentry": {
      "dsn": "http://sentry.acme.com"
    }

    "metrics": {
      # Optional. For sending metrics to Cloudwatch. If not set, metrics are not sent.
      "cloudwatch": {
        # Namespace that will contain the metrics in Cloudwatch
        "namespace": "snowplow/transformer_batch"

        # Name of the metric that contains the number of milliseconds needed to transform a folder
        "transformDuration": "transform_duration"

        # Any key-value pairs to be added as dimensions in Cloudwatch metrics
        "dimensions": {
          "app_version": "x.y.z",
          "env": "prod"
        }
      }
    }
  }
}
