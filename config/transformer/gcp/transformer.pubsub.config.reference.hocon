{
  "input": {
    # Name of the Pubsub subscription with the enriched events
    "subscription": "projects/project-id/subscriptions/subscription-id"

    # Optional. Default value 1. Number of threads used internally by permutive library to handle incoming messages.
    # These threads do very little "work" apart from writing the message to a concurrent Queue.
    "parallelPullCount": 1

    # Optional. Default value 500. The max size of the buffer queue used between fs2-pubsub and java-pubsub libraries.
    "bufferSize": 500

    # Optional. Default value '1 hour'. The maximum period a message ack deadline will be extended.
    "maxAckExtensionPeriod": "1 hour"

    # Optional. Sets a lower-bound on how the pubsub Subscriber extends ack deadlines.  Most relevant after the app
    # first starts up, until the underlying Subscriber has metrics on how long we take to process an event.
    "minDurationPerAckExtension": "60 seconds"
  }

  # Path to transformed archive
  "output": {
    # Path to transformer output
    "path": "gs://bucket/transformed/",
    # Transformer output compression, GZIP or NONE
    # Optional, default value GZIP
    "compression": "GZIP",

    # Optional section specifying details about badrows output. When unspecified, badrows are written as files under 'output.path' URI
    "bad": {
    
      # Type of output sink. Either 'pubsub' or 'file'. Optional, default value 'file'. When 'file', badrows are written as files under 'output.path' URI 
      "type": "pubsub",
      
      # Name of the PubSub topic that will receive the bad data
      "topic": "projects/project-id/topics/topic-id"
      
      # Optional. Maximum number of messages sent within a batch.
      # When the buffer reaches this number of messages they are sent.
      # PubSub maximum : 1000
      "batchSize": 1000      

      # Optional. Maximum number of bytes sent within a batch.
      # When the buffer reaches this size messages are sent.
      # Note the PubSub maximum is 10MB
      "requestByteThreshold": 8000000            
      
      # Optional. Delay threshold to use for batching.
      # After this amount of time has elapsed,
      # before maxBatchSize and maxBatchBytes have been reached,
      # messages from the buffer will be sent.
      "delayThreshold": 200 milliseconds
    }        
  }

  # Frequency to emit loading finished message - 5,10 etc minutes
  # Optional, default value 5 minutes
  # Note that there is a problem with acking messages when window period
  # is greater than 10 minute in transformer-pubsub. Therefore, it is
  # advisable to make window period equal or less than 10 minutes.
  "windowing": "5 minutes"

  # Name of the Pubsub topic used to communicate with Loader
  "queue": {
    "topic": "projects/project-id/topics/topic-id"
  }

  "formats": {
    # Optional. Denotes output file format.
    # Possible values are 'json' and 'parquet'. Default value 'json'.
    "fileFormat": "json"
  }

  # Events will be validated against given criterias and
  # bad row will be created if validation is not successful
  "validations": {
    "minimumTimestamp": "2021-11-18T11:00:00.00Z"
  }

  # Observability and reporting options
  "monitoring": {
    # Optional, for tracking runtime exceptions
    "sentry": {
      "dsn": "http://sentry.acme.com"
    }
    # Optional. How metrics are reported
    "metrics": {
      # Optional. Send metrics to a StatsD server (e.g. on localhost)
      "statsd": {
        "hostname": "localhost"
        "port": 8125
        "period": "1 minute"
        # Optional. Any key-value pairs to be tagged on every StatsD metric
        "tags": {
          "app": transformer
        }
        # Optional. Override the default metric prefix
        # "prefix": "snowplow.transformer."
      }
      # Optional. Log to stdout using Slf4j (logger name: transformer.metrics)
      "stdout": {
        "period": "1 minute"
        # Optional. Override the default metric prefix
        # "prefix": "snowplow.transformer."
      }
      # Optional. Send KCL metrics to Cloudwatch
      "cloudwatch": true
    }
  }

  # Optional. Configure telemetry
  # All the fields are optional
  "telemetry": {
    # Set to true to disable telemetry
    "disable": false
    # Interval for the heartbeat event
    "interval": 15 minutes
    # HTTP method used to send the heartbeat event
    "method": "POST"
    # URI of the collector receiving the heartbeat event
    "collectorUri": "collector-g.snowplowanalytics.com"
    # Port of the collector receiving the heartbeat event
    "collectorPort": 443
    # Whether to use https or not
    "secure": true
    # Identifier intended to tie events together across modules,
    # infrastructure and apps when used consistently
    "userProvidedId": "my_pipeline"
    # ID automatically generated upon running a modules deployment script
    # Intended to identify each independent module, and the infrastructure it controls
    "autoGeneratedId": "hfy67e5ydhtrd"
    # Unique identifier for the VM instance
    # Unique for each instance of the app running within a module
    "instanceId": "665bhft5u6udjf"
    # Name of the terraform module that deployed the app
    "moduleName": "transformer-pubsub-ce"
    # Version of the terraform module that deployed the app
    "moduleVersion": "1.0.0"
  }

  # Optional. Enable features that are still in beta, or which are here to enable smoother upgrades
  "featureFlags": {
    # Read/write in the legacy version 1 shredding complete message format.
    # This should be enabled during upgrade from older versions of the loader.
    "legacyMessageFormat": false
  
    # When enabled, event's atomic fields are truncated (based on the length limits from the atomic JSON schema) before transformation.
    # Optional, default "false".
    "truncateAtomicFields": false
  }
}
